[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Sam Weiner is an aspiring Data Scientist who is excited to bring creativity and analytical know-how to your data science team. I am a current masters student at the Institute for Advanced Analytics, where I am studying data science and technical communication to be able to solve complex problems and share results answers with a wide audience.\nI became interested in data science because of my growing curiosity. In my undergraduate philosophy courses, I enjoyed learning about and debating the answers to fascinating philosophical questions, but as my interests broadened from theoretical questions to practical ones, I realized that the skills I had as a philosopher were insufficient to answering real-word questions. When I heard about data science for the first time, I knew that becoming a data scientist was going to be my path forward to gaining a better understanding of our world. My curiosity has only grown as I have embarked on this journey, and I am so excited to dive into all of the data I can get my hands on to deepen my knowledge of the relationships and events that make up our endlessly fascinating world!\nMy journey has led me to become proficient in R, Python, and SQL. I have become intimately familiar with statistical learning techniques in the inferential world - linear regression, logistic regression, decision trees, causal inference - as well as in the predictive world - random forests, XGBoost, neural networks. I am leveraging Tableau and ggplot2 to create intuitive data visualizations to communicate data analysis to a broad audience.\nI am still passionate about big philosophical questions, and I love to have stimulating conversations with my friends or strangers! In my free time, you might see me watching college wrestling (Go RU!) or obsessing over the perfect hummus recipe."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nRutgers University | New Brunswick, NJ\nB.A. in Philosophy | Sept 2018 - May 2021\nInstitute for Advanced Analytics, North Carolina State University | Raleigh, NC\nM.S. Candidate in Analytics | June 2022 - Current"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dialectic with Data",
    "section": "",
    "text": "R resources for Practicum\n\n\n\n\n\n\n\n\n\n\n\n\nSam Weiner\n\n\n\n\n\n\n\n\nTidy Tuesday - World Cup Edition\n\n\n\n\n\n\n\ntidytuesday\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2022\n\n\nSam Weiner\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 8, 2022\n\n\nSam Weiner\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/R-resources/index.html",
    "href": "posts/R-resources/index.html",
    "title": "R resources for Practicum",
    "section": "",
    "text": "Hello again! I’m excited to put another post up on Dialectic with Data where I will be brain dumping some of the awesome R resources I have ran across in my journey learning and loving R! This post is was specifically inspired by my practicum team because I have enjoyed sharing these resources with them over time, but many of them have been lost deep in the depths of our slack channel. So, I am going to be cataloging many of the things that I have shared with them, and I will also be adding new resources as I come upon them for them and you!"
  },
  {
    "objectID": "posts/R-resources/index.html#general-r-tips",
    "href": "posts/R-resources/index.html#general-r-tips",
    "title": "R resources for Practicum",
    "section": "1 General R tips",
    "text": "1 General R tips\n\n1.1 R for Data Science\nMy biggest and most valuable tip to learning R is read R for Data Science by Hadley Wickham and Garret Grolemund.This book has so much knowledge stored inside it. It primarily teaches the tidyverse and its wonderful array of tools for exploratory data analysis and data visualization. It has been a bible for me, and I see myself turning back to it more often than one would think for a self-classified introductory book. The second version is currently under development but available to read here.\n\n\n1.2 Rstudio Projects\nRstudio projects are a convenient and efficient way of organizing all of the code, data, and visualizations that make up a data science project. The biggest efficiency boost in my experience is that your working directory automatically updates to the folder where your Rstudio project lives, so all of you code and visualizations are automatically saved in the same place. Additionally, any data that you have in, for example, a csv file can be easily uploaded to your environment without having to mess with the working directory. Other important features that are a bit more advanced revolve around Rstudio projects ability to improve reproducibility and use version control.\n\nResources for learning more about Rstudio Projects\n\nIntro to Rstudio Projects\nRstudio and reproducibility\nRstudio and git\n\n\n\n\n1.3 Shortcuts, Tips, and Tricks\nThe Rstudio IDE is probably the best IDE (integrated development environment) for using R and conducting data science tasks in general. It has stiff competition from the likes of Visual Studio Code, but there are a few tips and tricks that I am going to show you for Rstudio that might make you think twice before switching to a different IDE.\n\nAlt + -\n\nShortcut for inserting the assignment operator <-\n\nCtrl + Shift + M\n\nShortcut for inserting the pipe magrittr operator %>% commonly used in the tidyverse\nNote: As of R 4.1.0, R has a built in pipe operator |> which works similarly to the magrittr pipe but has same slight nuances. See here and here for more information on the built in pipe operator.\n\n\nCtrl + Shift + R\n\nCreates a comment section header in an R source file which is collapsible and also creates an outline to easily navigate your code file.\n\nCtrl + Shift + Alt + M\n\nRenames a variable in the entire file. Just highlight the variable to be renamed, use the shortcut, and type the new name. Easy as that!\nUsing Ctrl + F and using replace is another option which is useful when you don’t want to rename every instance of a variable in the file.\n\nCode Snippets\n\nCode Snippets are ways to insert commonly used code structures (or headers) in an R file. Under the Tools toolbar, go to Edit Code Snippets. There you will see all the code snippets pre-built in Rstudio and and editor for adding new ones. I use this to add a header structure to new scripts where I can fill in information about the script for my teammates to read when they use it.\n\nMultiple Cursors\n\nThis was a tip that I was sorely missing from my time using VS Code until I stumbled upon this simple shortcut in Rstudio! Just by holding down the Alt button and clicking or draging with the mouse, you’ll have more cursors than you know what to do with.\n\n\nMore awesome shortcuts can be found in this awesome article by Appsilon\n\n\n1.4 Quarto\nQuarto is Rstudio’s (now called Posit) new Rmarkdown replacement. The biggest change from Rmarkdown to Quarto is that you can use Quarto in Jupyter Notebooks! Posit (formerly Rstudio) is broadening it’s presence in the data science community by engaging with python users in addition to R users. The hope, says Posit, is to create easy tools for cross-language collaboration so that researchers and data scientists who have different languages of choice can work together with ease. From what I have seen, many data scientists who might have preferred R as a language have been pressured to use python because of its large presence in the data science community. This tool is hopefully going to create a pathway for R users to stay R users without complicating team workflows in a python-dominant environment.\nIn addition, Quarto has some awesome features such as helping users easily create documents, presentation, or even blogs (like this one!). So far, it has been very intuitive and the documentation has been very helpful. You can find information at quarto.org."
  },
  {
    "objectID": "posts/R-resources/index.html#packages",
    "href": "posts/R-resources/index.html#packages",
    "title": "R resources for Practicum",
    "section": "2 Packages",
    "text": "2 Packages\nNow lets get to packages! I am going to be listing packages that I think are really helpful (and really cool) for working with data and doing modeling in R.\n\n2.1 Tidyverse\n\nggplot2\n\nThis package contains the best tools for taking data and making a stellar visualization out of it. It is extremely versatile and at times very complicated. Later on I will be sharing more about ggplot2 and provide some resources for making ggplot2 super easy to understand.\n\ndplyr\n\nThis package has the tools you need to manipulate data. Mutate is useful for feature engineering and summarise is great for calculating summaries of your data set. Using the piping syntax makes this package so powerful. My favorite way of using this package is to dig into the data and pipe what I want into a ggplot!\n\nreadr\n\nThis package makes importing data easy as can be.\n\npurrr\n\nThis package contains the tidyverse’s toolkit for functional programming. The iteration chapter in R for Data Science is a great place to start if you are new to functional programming. Another great resources I used is purrr tutorial by Jenny Bryan. Functional programming has been very hard for me, but these two resources have really helped me wrap my brain around the concept, and it has already impacted by projects enormously.\n\nstringr\n\nstringr is the handiest way of working with strings in R. It has everything under the sun when it comes to manipulating and cleaning character data.\n\nforcats\n\nFactors are a very common data type in R, but they can be tricky at times. This package has some awesome tools for working with factors that will really come in handy if you use factors a lot.\n\n\n\n\n2.2 Tidymodels\nTidymodels is a standalone universe which has everything you need to do machine learning in R. The tidymodels project is headed by the same person that create CARET years back, Max Kuhn, and the goal of tidymodels is the same as CARETS goal: To create a unified interface for machine learning in R. The package makes use of R’s rich ecosystem of machine learning model packages but standardizes the interface across all those implementations to make the switch between models seamless. The amount of packages and tools in the tidymodels universe is large and there is too much to say for this blog post. However, I do plan on showing how tidymodels is used in a future blog post, so stay tuned! In the meantime, I am going to point you to some amazing resources if you want to get started now.\n\nTidy Modeling with R is a free book written by Max Kuhn and Julia Silge which is the best resource for getting started with tidymodels and it also has some great information on machine learning in general!\ntidymodels.org has some amazing content which will be the preferred resource for people who want a shorter format introduction to tidymodels.\njuilasilge.com is the blog of one of the co-authors of Tidy Modeling with R and she has some great blog posts and youtube videos where she implements the tidymodels packages and gives great explanations of what she is doing.\n\n\n\n2.3 Awesome Packages\nThe Awesome Packages section is going to be a growing list of packages that I find really cool because they have either changed and/or improved the way I use R as a data science student.\n\n2.3.1 broom\nbroom is a super cool R package. One of the most annoying aspects of using R for data science is trying to extract the output from the model object. Summaries of the model object are easy enough to get using summary(), but to extract the components of model like the coefficients, pvalues, or Rsquared value to use for other operations means digging into the model object and trying and failing to use the right index to find it. broom makes that task no more. By using the tidy() function on supported model objects, the output is represented as a data frame which makes extracting what you want so much easier. Rsquared and other metric vaules can be found by using glance() and augment() can add output like predictions from a new datas et back into the data set from whence it came.\n\n\n2.3.2 janitor\njanitor is a key package because it does something that, while we might think is important, is not all that interesting, but is a such a quality of life boost for a data scientist. Cleaning dirty data is numerous ways. Cleaning dirty data is a necessary part of the process to extracting value out a data set, but it is such a time sink. Janitor comes in to provide a myriad of helpful functions to get data people working in the data instead of on the data.\n\n\n2.3.3 skimr\nskimr is your best friend when beginning exploratory data analysis. Using the skim() function on a data frame, a really easy to understand output will be generated containing summary statistics for all of your columns. The information will include variable type, percent missing, 0th, 25th, 50th, 75th, 100th percentile value for continuous variables, mean, standard deviation, and more! I think that you will love this tool once you start to use it!\n\n\n2.3.4 reprex\nWe all know what it’s like to feel completely baffled when writing code. At least I can say I have felt completely baffled when writing code and I have felt stuck countless times. And when I am baffled, I go to the internet to find the cure. If I ever have to ask a question on sites like stack overflow or github to ask for help, I always use reprex to help me create a minimally reproducible example. A minimally reproducible example is simple piece of code that replicates your problem so that other knowledgeable people can help you diagnose your issue. Asking questions with reprex gives you the best chance to finding an answer to your question because you have helped the internet help you by giving them the exact situation you are facing."
  },
  {
    "objectID": "posts/R-resources/index.html#ggplot2",
    "href": "posts/R-resources/index.html#ggplot2",
    "title": "R resources for Practicum",
    "section": "3 ggplot2",
    "text": "3 ggplot2\nggplot2 is the primary visualization package in R. It allows for extreme creativity when turning data into visualizations. Checkout the #tidytuesday hashtag on twitter to see some of the crazy impressive visualizations made with ggplot2! ggplot2 is not a package that is simple to master, however. For those beginning their journey with ggplot2, I recommend R for Data Science’s chapter on data visualization which gives a great explanation behind the design of ggplot2 and how it is meant to be used. If you need a reference for ggplot2 code, R Graphics Cookbook is a great resource as are the R Graph Gallery and R charts. I find that sometimes I need to understand how ggplot2 takes data and makes visuals out of it, which is what R for Data Science is great for, and other times I just need a resource to show me all the cool ways I can represent my data, which is what those other three resources are there for.\n\n3.1 Extensions\nOne major benefit of ggplot2 being the default visualization package in R is that it has been building blocks of choice for so many R programmers create new visualization capabilities in R and ggplot2. There are hundreds of extension packages for ggplot2 that add onto its functionality in incredible ways. For instance, gganimate creates the ability for you to have animated graphics in R! And the best part is that these extensions are usually very easy to learn because they all use the same ggplot2 mechanics as I was saying earlier. A full list of registered extensions can be found here.\nOne really exquisite ggplot extension I would like to highlight is esquisse. This package creates a tableau-like interface inside of Rstudio, so that we can interactively plot our data! It has been a game changer for me when doing EDA.\n\n\n3.2 Fonts\nOne way that people like to modify their visualizations from base ggplot2 is by modifying text fonts. Packages like extrafont and showtext make doing this extremely easy. hrbrthemes is an example of pre-built themes that R users have created that take try to enhance ggplot2 output in this way.\n\n\n3.3 Scales\nScaling is a crucial part of effective data communication. If the scale of the data is not clear, then any inferences from that communication will either be unclear or misled. The scales package provides some awesome tooling to make very clear and descriptive plot scales."
  },
  {
    "objectID": "posts/R-resources/index.html#causal-inference",
    "href": "posts/R-resources/index.html#causal-inference",
    "title": "R resources for Practicum",
    "section": "4 Causal Inference",
    "text": "4 Causal Inference\nCausal inference is a topic that I have been learning about a lot lately. As someone who does not have a formal background in statistics or epidemiology, it has been important to me to find resources that teach causal inference in terms that I can understand. Here is a list of resources and R packages that can help you if you are interested in causal inference.\n\nCausal Inference in R is a ongoing book project by Malcolm Barrett, Lucy D’Agostino McGowan, and Travis Gerke. It contains some amazing information at the moment and it will only get better as the authors work on it.\nCausal Inference for The Brave and True by Matheus Facure Alves is a book that has great explanations of causal inference techniques and concepts and everything coding related is written in python for those interested in a python implementation of causal inference!\nCausal Inference: What If? by Miguel A. Hernán and James M. Robins is causal inference bible. It is much heavier than the resources above and the focus is purely on the methodology of causal inference. However R code which follows part 2 of the book chapter by chapter can be found here.\nWorkshop: Causal Inference in R is a video workshop by Malcolm Barrett and Lucy D’Agostino McGowan. The workshop has been updated since the video but no new video has surfaced that I could find. The new workshop can be found on github here with the slides and exercise rmarkdown files. The solutions to the exercises can be found here.\nMatchIt is a package that creates matches based on observational data. It has awesome vignettes on its website that explains matching for causal inference in detail and has many method options to implement for matching.\nggdag is a way to plot directed acyclic dags (DAGs) in R using more a ggplot2-like interface as opposed to daggity.\npropensity helps calculate propensity scores and weights for a wide variety of research questions.propensity is under very early development.\ntipr After fitting your model, you can determine the unmeasured confounder needed to tip your analysis.\nhalfmoon The goal of halfmoon is to cultivate balance in propensity score models."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Hello World!\nI am excited to start this blog where I will share my journey learning data science. I hope to share data analysis that I have conducted using the awesome tool-kit I have gained at the Institute for Advanced Analytics, some R packages that I think are cool, and my thoughts on the field of data science as a whole. Cheers to a new adventure!\n- Sam"
  },
  {
    "objectID": "posts/world-cup/index.html",
    "href": "posts/world-cup/index.html",
    "title": "Tidy Tuesday - World Cup Edition",
    "section": "",
    "text": "Tidy Tuesday is an awesome initiative by the R for Data Science Community where data sets are published every week for the R community share any analysis and visualizations that can be conjured from the data!\n\n\nThis data set contains data on every World Cup since 1930.\n\nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(tidymodels)\ntheme_set(theme_light())\n\n\n\n\n\ntt <- tt_load(\"2022-11-29\")\ntt\n\nThis episode of Tidy Tuesday contains two data sets. wcmatches (matches from now on) contains 900 rows, one for each game played on the World Cup stage. It has variables for who played who, what stage (or round) of the tournament the game was played, who won, and the goals scored by each team.\n\nmatches <- tt$wcmatches\nglimpse(matches)\n\nRows: 900\nColumns: 15\n$ year           <dbl> 1930, 1930, 1930, 1930, 1930, 1930, 1930, 1930, 1930, 1…\n$ country        <chr> \"Uruguay\", \"Uruguay\", \"Uruguay\", \"Uruguay\", \"Uruguay\", …\n$ city           <chr> \"Montevideo\", \"Montevideo\", \"Montevideo\", \"Montevideo\",…\n$ stage          <chr> \"Group 1\", \"Group 4\", \"Group 2\", \"Group 3\", \"Group 1\", …\n$ home_team      <chr> \"France\", \"Belgium\", \"Brazil\", \"Peru\", \"Argentina\", \"Ch…\n$ away_team      <chr> \"Mexico\", \"United States\", \"Yugoslavia\", \"Romania\", \"Fr…\n$ home_score     <dbl> 4, 0, 1, 1, 1, 3, 0, 0, 1, 6, 1, 0, 0, 4, 3, 6, 6, 4, 2…\n$ away_score     <dbl> 1, 3, 2, 3, 0, 0, 4, 3, 0, 3, 0, 1, 4, 0, 1, 1, 1, 2, 3…\n$ outcome        <chr> \"H\", \"A\", \"A\", \"A\", \"H\", \"H\", \"A\", \"A\", \"H\", \"H\", \"H\", …\n$ win_conditions <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ winning_team   <chr> \"France\", \"United States\", \"Yugoslavia\", \"Romania\", \"Ar…\n$ losing_team    <chr> \"Mexico\", \"Belgium\", \"Brazil\", \"Peru\", \"France\", \"Mexic…\n$ date           <date> 1930-07-13, 1930-07-13, 1930-07-14, 1930-07-14, 1930-0…\n$ month          <chr> \"Jul\", \"Jul\", \"Jul\", \"Jul\", \"Jul\", \"Jul\", \"Jul\", \"Jul\",…\n$ dayofweek      <chr> \"Sunday\", \"Sunday\", \"Monday\", \"Monday\", \"Tuesday\", \"Wed…\n\n\nworldcups (wcups from now on) has information about each world cup on a high level. It contains information like the name of the host country each World Cup, the names of the top four finishers, total tournament goals scored, and the number of teams, games, and attendants.\n\nwcups <- tt$worldcups\nglimpse(wcups)\n\nRows: 21\nColumns: 10\n$ year         <dbl> 1930, 1934, 1938, 1950, 1954, 1958, 1962, 1966, 1970, 197…\n$ host         <chr> \"Uruguay\", \"Italy\", \"France\", \"Brazil\", \"Switzerland\", \"S…\n$ winner       <chr> \"Uruguay\", \"Italy\", \"Italy\", \"Uruguay\", \"West Germany\", \"…\n$ second       <chr> \"Argentina\", \"Czechoslovakia\", \"Hungary\", \"Brazil\", \"Hung…\n$ third        <chr> \"USA\", \"Germany\", \"Brazil\", \"Sweden\", \"Austria\", \"France\"…\n$ fourth       <chr> \"Yugoslavia\", \"Austria\", \"Sweden\", \"Spain\", \"Uruguay\", \"W…\n$ goals_scored <dbl> 70, 70, 84, 88, 140, 126, 89, 89, 95, 97, 102, 146, 132, …\n$ teams        <dbl> 13, 16, 15, 13, 16, 16, 16, 16, 16, 16, 16, 24, 24, 24, 2…\n$ games        <dbl> 18, 17, 18, 22, 26, 35, 32, 32, 32, 38, 38, 52, 52, 52, 5…\n$ attendance   <dbl> 434000, 395000, 483000, 1337000, 943000, 868000, 776000, …"
  },
  {
    "objectID": "posts/world-cup/index.html#world-cup-dataset",
    "href": "posts/world-cup/index.html#world-cup-dataset",
    "title": "Tidy Tuesday - World Cup Edition",
    "section": "World Cup dataset",
    "text": "World Cup dataset\nAs was mentioned above, the World Cup dataset contains more general information about each World Cup.\n\nwcups\n\n# A tibble: 21 × 10\n    year host        winner      second third fourth goals…¹ teams games atten…²\n   <dbl> <chr>       <chr>       <chr>  <chr> <chr>    <dbl> <dbl> <dbl>   <dbl>\n 1  1930 Uruguay     Uruguay     Argen… USA   Yugos…      70    13    18  434000\n 2  1934 Italy       Italy       Czech… Germ… Austr…      70    16    17  395000\n 3  1938 France      Italy       Hunga… Braz… Sweden      84    15    18  483000\n 4  1950 Brazil      Uruguay     Brazil Swed… Spain       88    13    22 1337000\n 5  1954 Switzerland West Germa… Hunga… Aust… Urugu…     140    16    26  943000\n 6  1958 Sweden      Brazil      Sweden Fran… West …     126    16    35  868000\n 7  1962 Chile       Brazil      Czech… Chile Yugos…      89    16    32  776000\n 8  1966 England     England     West … Port… Sovie…      89    16    32 1614677\n 9  1970 Mexico      Brazil      Italy  West… Urugu…      95    16    32 1673975\n10  1974 Germany     West Germa… Nethe… Pola… Brazil      97    16    38 1774022\n# … with 11 more rows, and abbreviated variable names ¹​goals_scored,\n#   ²​attendance\n\n\nWe can count the number of total goals scored in a World Cup and rank them by which tournament had the most goals scored.\n\nwcups %>% \n  count(year, wt = goals_scored, sort = TRUE)\n\n# A tibble: 21 × 2\n    year     n\n   <dbl> <dbl>\n 1  1998   171\n 2  2014   171\n 3  2018   169\n 4  2002   161\n 5  2006   147\n 6  1982   146\n 7  2010   145\n 8  1994   141\n 9  1954   140\n10  1986   132\n# … with 11 more rows\n\n\nLet’s also visualize the relationship between number of goals scored and the number of matches played in each World Cup.\n\nwcups %>% \n  ggplot(aes(year, goals_scored)) +\n  geom_line() +\n  geom_line(aes(year, games))"
  }
]